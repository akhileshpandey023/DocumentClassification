{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###R preprocessing Code\n",
    "##reutersImportantCSV <- reutersCSV[,c(\"pid\",\"fileName\",\"purpose\",\"topic.earn\",\\\n",
    "##\"topic.acq\", \"topic.money.fx\",\"topic.grain\", \"topic.crude\", \"topic.trade\", \"topic.interest\",\\\n",
    "##\"topic.ship\",\"topic.wheat\",\"topic.corn\",\"doc.title\",\"doc.text\")]\n",
    "\n",
    "##reutersNUImportantCSV <- reutersImportantCSV[which(reutersImportantCSV$purpose=='not-used'),]\n",
    "\n",
    "##reutersTestImportantCSV <- reutersImportantCSV[which(reutersImportantCSV$purpose=='test'),]\n",
    "\n",
    "##reutersTrainImportantCSV <- reutersImportantCSV[which(reutersImportantCSV$purpose=='train'),]\n",
    "\n",
    "##write.csv(reutersNUImportantCSV, file = \"reutersNUImportantCSV.csv\",row.names=TRUE, na=\"\")\n",
    "\n",
    "##write.csv(reutersTestImportantCSV, file = \"reutersTestImportantCSV.csv\",row.names=TRUE, na=\"\")\n",
    "\n",
    "##write.csv(reutersTrainImportantCSV, file = \"reutersTrainImportantCSV.csv\",row.names=TRUE, na=\"\")\n",
    "\n",
    "##write.csv(reutersImportantCSV, file = \"reutersImportantCSV.csv\",row.names=TRUE, na=\"\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Sets/changes the directory to the document directory\n",
    "os.chdir(\"/Users/Akhilesh Pandey/Desktop/art_corpus/ART_Corpus\")\n",
    "\n",
    "#Reading the Training file and saving into data frame\n",
    "reutersTrainDataSet=pd.read_csv(\"reutersTrainImportantCSV.csv\",encoding='iso-8859-1',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15373\n",
      "15373\n",
      "14668\n"
     ]
    }
   ],
   "source": [
    "#We will combine the topics and the text of each row and create an entry\n",
    "#in the class List as the class for which the value is '1'\n",
    "\n",
    "classList=[]\n",
    "textList=[]\n",
    "textCombination=[]\n",
    "textCombination = reutersTrainDataSet['doc.title'].map(str) + ' '+ reutersTrainDataSet['doc.text']\n",
    "#Looking for condition '1'. Also flag remains 'False' if all the 10 topics have 0 value\n",
    "for i in range(0, len(reutersTrainDataSet)):\n",
    "    flag= False\n",
    "    if reutersTrainDataSet['topic.earn'][i]==1:\n",
    "        classList.append('topic.earn')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.money.fx'][i]==1:\n",
    "        classList.append('topic.money.fx')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.acq'][i]==1:\n",
    "        classList.append('topic.acq')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.grain'][i]==1:\n",
    "        classList.append('topic.grain')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.crude'][i]==1:\n",
    "        classList.append('topic.crude')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.trade'][i]==1:\n",
    "        classList.append('topic.trade')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.interest'][i]==1:\n",
    "        classList.append('topic.interest')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.ship'][i]==1:\n",
    "        classList.append('topic.ship')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.wheat'][i]==1:\n",
    "        classList.append('topic.wheat')        \n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTrainDataSet['topic.corn'][i]==1:\n",
    "        classList.append('topic.corn')\n",
    "        textList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if flag is False:\n",
    "        classList.append('No Class')\n",
    "        textList.append(textCombination[i])\n",
    "print(len(classList))\n",
    "print(len(textList))\n",
    "print(len(reutersTrainDataSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "st = LancasterStemmer()\n",
    "\n",
    "# Stores the stopwords in english in a set called stop\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "def process_words(words):\n",
    "    \n",
    "    # Initialising the list to store the stop words\n",
    "    wordList= []\n",
    "    wordLemmaList= []\n",
    "    wordStemList = []\n",
    "    \n",
    "    # Converts all the uppercase in the Tweets to lowercase\n",
    "    words=words.lower()\n",
    "    \n",
    "    #Removing the special symbols such as ',','.', etc.\n",
    "    words = re.sub(r'[^a-zA-Z0-9 ]',r'',words)\n",
    "    \n",
    "    #Converting stream of words to a list of words to check for stop words\n",
    "    wordList= words.split()\n",
    "    \n",
    "    #Performing Lemmatisation\n",
    "    for words in wordList:\n",
    "        wordLemmaList.append(lmtzr.lemmatize(words))\n",
    "        \n",
    "    #Performing Word Stemming\n",
    "    for words in wordList:        \n",
    "        wordStemList.append(st.stem(words))\n",
    "    \n",
    "    #Removing the stopwords from the List of words and joins the words into string\n",
    "    for words in wordStemList:\n",
    "        if words in stop:\n",
    "            wordStemList.remove(words)\n",
    "    return(\" \".join(wordStemList))\n",
    "\n",
    "clean_text=[]\n",
    "\n",
    "num_rows= len(textList)\n",
    "#Iterating through each row and proessing the text.\n",
    "#We're saving this output in clean_text List\n",
    "for i in range(0, num_rows):\n",
    "    clean_text.append(process_words(str(textList[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialising the Vectoriser based on processed Tweets and taking max_features 1000\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",ngram_range=(1,3), max_features=1500, stop_words = None) \n",
    "\n",
    "#Creating the vectorizer for clean_text List \n",
    "#Also we are fitting the vectorizer \n",
    "text_features = vectorizer.fit_transform(clean_text)\n",
    "\n",
    "# Converts the feature matrix to an array\n",
    "text_features = text_features.toarray()\n",
    "\n",
    "print(type(text_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a K-fold function\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "text_features_list = text_features.tolist()\n",
    "#The function splits the featureList and the classList based on the 'folds'\n",
    "#The output will be 4 lists. The devided feature List and divided class List\n",
    "def k_fold_generator(featureList, classList, folds):    \n",
    "    subset_size = int(len(featureList) / folds)  \n",
    "    for k in range(folds):\n",
    "        featureList_train = featureList[:k * subset_size] + featureList[(k + 1) * subset_size:]\n",
    "        featureList_test = featureList[k * subset_size:][:subset_size]\n",
    "        classList_train = classList[:k * subset_size] + classList[(k + 1) * subset_size:]\n",
    "        classList_test = classList[k * subset_size:][:subset_size]\n",
    "        yield featureList_train, classList_train, featureList_test, classList_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635653871178\n",
      "0.66753415745\n",
      "0.646063760573\n",
      "0.666883539362\n",
      "0.666883539362\n",
      "0.661027976578\n",
      "0.635653871178\n",
      "0.62589459987\n",
      "0.642160052049\n",
      "0.446324007807\n"
     ]
    }
   ],
   "source": [
    "#Testing on Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "#We will use the function created above and use it to create 10 seaprate sub sections of the data set\n",
    "#While the 9 of the sections will be used for training, the other 10th will be used for testing\n",
    "#We will iterate 10 times until we have covered all the subsections as test dataset\n",
    "#the .score function gives the accuracy of the prediction\n",
    "text_features_list = text_features.tolist()         \n",
    "for featureList_train, classList_train, featureList_test, classList_test in k_fold_generator(text_features_list,classList,10):\n",
    "    featureList_train = np.asarray(featureList_train)\n",
    "    classList_train = np.asarray(classList_train)\n",
    "    mnb.fit(featureList_train,classList_train)  #The .score method produces \n",
    "    score = mnb.score(featureList_test,classList_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793754066363\n",
      "0.797657774886\n",
      "0.750813272609\n",
      "0.788549121666\n",
      "0.805465191932\n",
      "0.75992192583\n",
      "0.780091086532\n",
      "0.753415744958\n",
      "0.737150292778\n",
      "0.867273910215\n"
     ]
    }
   ],
   "source": [
    "#Testing on Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "#We are doing the same thing for the Random Forest Classifier. The parameters havebeen discussed\n",
    "#in the report.\n",
    "text_features_list = text_features.tolist()        \n",
    "for featureList_train, classList_train, featureList_test, classList_test in k_fold_generator(text_features_list,classList,10):\n",
    "    featureList_train = np.asarray(featureList_train)\n",
    "    classList_train = np.asarray(classList_train)\n",
    "    forest.fit(featureList_train,classList_train)\n",
    "    score = forest.score(featureList_test, classList_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79440468445\n",
      "0.793103448276\n",
      "0.754716981132\n",
      "0.790500975927\n",
      "0.802212101496\n",
      "0.763825634353\n",
      "0.776837996096\n",
      "0.74821080026\n",
      "0.730644111906\n",
      "0.880936890046\n"
     ]
    }
   ],
   "source": [
    "#Testng on SVM\n",
    "from sklearn import svm\n",
    "import numpy as np \n",
    "svm = svm.SVC(kernel='rbf') \n",
    "\n",
    "#We are using the 'rbf' kernel as this it is the most efficient kernel for \n",
    "#text classification\n",
    "\n",
    "text_features_list = text_features.tolist()   \n",
    "for featureList_train, classList_train, featureList_test, classList_test in k_fold_generator(text_features_list,classList,10):\n",
    "    featureList_train = np.asarray(featureList_train)\n",
    "    classList_train = np.asarray(classList_train)\n",
    "    svm.fit(featureList_train,classList_train)\n",
    "    score = svm.score(featureList_test, classList_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading the Test file \n",
    "reutersTestDataSet=pd.read_csv(\"reutersTestImportantCSV.csv\",encoding='iso-8859-1',sep=',')\n",
    "#Doing test test processing similar to train data set\n",
    "classTestList=[]\n",
    "textTestList=[]\n",
    "textCombination=[]\n",
    "textCombination = reutersTestDataSet['doc.title'].map(str) + ' '+ reutersTrainDataSet['doc.text']\n",
    "for i in range(0, len(reutersTestDataSet)):\n",
    "    flag= False\n",
    "    if reutersTestDataSet['topic.earn'][i]==1:\n",
    "        classTestList.append('topic.earn')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.money.fx'][i]==1:\n",
    "        classTestList.append('topic.money.fx')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.acq'][i]==1:\n",
    "        classTestList.append('topic.acq')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.grain'][i]==1:\n",
    "        classTestList.append('topic.grain')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.crude'][i]==1:\n",
    "        classTestList.append('topic.crude')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.trade'][i]==1:\n",
    "        classTestList.append('topic.trade')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.interest'][i]==1:\n",
    "        classTestList.append('topic.interest')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.ship'][i]==1:\n",
    "        classTestList.append('topic.ship')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.wheat'][i]==1:\n",
    "        classTestList.append('topic.wheat')        \n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if reutersTestDataSet['topic.corn'][i]==1:\n",
    "        classTestList.append('topic.corn')\n",
    "        textTestList.append(textCombination[i])\n",
    "        flag = True\n",
    "    if flag is False:\n",
    "        classTestList.append('No Class')\n",
    "        textTestList.append(textCombination[i])\n",
    "\n",
    "clean_test_text=[]\n",
    "\n",
    "num_rows= len(textTestList)\n",
    "\n",
    "for i in range(0, num_rows):\n",
    "    clean_test_text.append(process_words(str(textList[i])))\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_text)\n",
    "\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 20) \n",
    "predictRFModel = forest.fit(text_features,classList)\n",
    "\n",
    "#Implementing Random Forest\n",
    "resultRF = predictRFModel.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training the Naive Bayes Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "predictNBModel = mnb.fit(text_features,classList)\n",
    "\n",
    "#Implementing Naive Bayes\n",
    "resultNB = predictNBModel.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the SVM Model\n",
    "from sklearn import svm\n",
    "import numpy as np \n",
    "svm = svm.SVC(kernel='rbf') \n",
    "predictSVMModel = svm.fit(text_features,classList)\n",
    "\n",
    "#Implementing SVM\n",
    "resultSVM = predictSVMModel.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               |                                  t    t                |\n",
      "               |                                  o    o                |\n",
      "               |                                  p    p                |\n",
      "               |                   t         t    i    i         t    t |\n",
      "               |              t    o    t    o    c    c    t    o    o |\n",
      "               |         t    o    p    o    p    .    .    o    p    p |\n",
      "               |    N    o    p    i    p    i    i    m    p    i    i |\n",
      "               |    o    p    i    c    i    c    n    o    i    c    c |\n",
      "               |         i    c    .    c    .    t    n    c    .    . |\n",
      "               |    C    c    .    c    .    g    e    e    .    t    w |\n",
      "               |    l    .    c    r    e    r    r    y    s    r    h |\n",
      "               |    a    a    o    u    a    a    e    .    h    a    e |\n",
      "               |    s    c    r    d    r    i    s    f    i    d    a |\n",
      "               |    s    q    n    e    n    n    t    x    p    e    t |\n",
      "---------------+--------------------------------------------------------+\n",
      "      No Class |<2008> 367   46  103  695   95   65   89   57   80   35 |\n",
      "     topic.acq |  406  <74>  15   19  130   22    9   19    5   15    5 |\n",
      "    topic.corn |   40    6   <.>   .    7    .    1    1    .    .    1 |\n",
      "   topic.crude |   92   26    4   <5>  37    9    2    5    3    2    4 |\n",
      "    topic.earn |  594  106   18   32 <212>  40   16   25   12   22   11 |\n",
      "   topic.grain |   71   16    .    2   38   <7>   3    4    1    3    4 |\n",
      "topic.interest |   68   18    2    3   28    4   <3>   3    2    2    . |\n",
      "topic.money.fx |   95   24    .    2   41    8    4   <5>   .    1    . |\n",
      "    topic.ship |   54    9    .    3   11    1    .    4   <2>   4    1 |\n",
      "   topic.trade |   59   11    1    2   21    8    1    7    2   <3>   2 |\n",
      "   topic.wheat |   42    6    .    2    8    5    .    2    3    .   <3>|\n",
      "---------------+--------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the Confusion Matrix Random Forest\n",
    "from nltk.metrics import ConfusionMatrix \n",
    "import numpy as np\n",
    "\n",
    "trueValues =  classTestList\n",
    "calculatedValues = resultRF.tolist()\n",
    "confusionMatrixRF = ConfusionMatrix(trueValues, calculatedValues)\n",
    "print(confusionMatrixRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               |                                  t    t                |\n",
      "               |                                  o    o                |\n",
      "               |                                  p    p                |\n",
      "               |                   t         t    i    i         t    t |\n",
      "               |              t    o    t    o    c    c    t    o    o |\n",
      "               |         t    o    p    o    p    .    .    o    p    p |\n",
      "               |    N    o    p    i    p    i    i    m    p    i    i |\n",
      "               |    o    p    i    c    i    c    n    o    i    c    c |\n",
      "               |         i    c    .    c    .    t    n    c    .    . |\n",
      "               |    C    c    .    c    .    g    e    e    .    t    w |\n",
      "               |    l    .    c    r    e    r    r    y    s    r    h |\n",
      "               |    a    a    o    u    a    a    e    .    h    a    e |\n",
      "               |    s    c    r    d    r    i    s    f    i    d    a |\n",
      "               |    s    q    n    e    n    n    t    x    p    e    t |\n",
      "---------------+--------------------------------------------------------+\n",
      "      No Class |<1286> 747   94  128  680   92  141   73  126  192   81 |\n",
      "     topic.acq |  263 <165>  23   21  125   17   31    9   21   28   16 |\n",
      "    topic.corn |   23   16   <2>   .    8    1    2    .    1    2    1 |\n",
      "   topic.crude |   57   45    8   <7>  34    6    7    6    4    7    8 |\n",
      "    topic.earn |  391  227   31   41 <191>  27   45   25   34   52   24 |\n",
      "   topic.grain |   48   31    2    3   36   <2>   4    5    3    7    8 |\n",
      "topic.interest |   50   27    4    5   27    .   <5>   4    2    7    2 |\n",
      "topic.money.fx |   62   39    3    3   45    7    6   <5>   6    2    2 |\n",
      "    topic.ship |   36   17    .    3   10    .    4    3   <4>  10    2 |\n",
      "   topic.trade |   37   27    4    2   20    1    5    5    5   <5>   6 |\n",
      "   topic.wheat |   25   11    .    .   10    3    3    .    6    5   <8>|\n",
      "---------------+--------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the Confusion Matrix Naive Bayes\n",
    "from nltk.metrics import ConfusionMatrix \n",
    "import numpy as np\n",
    "\n",
    "trueValues =  classTestList\n",
    "calculatedValues = resultNB.tolist()\n",
    "confusionMatrixNB = ConfusionMatrix(trueValues, calculatedValues)\n",
    "print(confusionMatrixNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               |                                  t    t                |\n",
      "               |                                  o    o                |\n",
      "               |                                  p    p                |\n",
      "               |                   t         t    i    i         t    t |\n",
      "               |              t    o    t    o    c    c    t    o    o |\n",
      "               |         t    o    p    o    p    .    .    o    p    p |\n",
      "               |    N    o    p    i    p    i    i    m    p    i    i |\n",
      "               |    o    p    i    c    i    c    n    o    i    c    c |\n",
      "               |         i    c    .    c    .    t    n    c    .    . |\n",
      "               |    C    c    .    c    .    g    e    e    .    t    w |\n",
      "               |    l    .    c    r    e    r    r    y    s    r    h |\n",
      "               |    a    a    o    u    a    a    e    .    h    a    e |\n",
      "               |    s    c    r    d    r    i    s    f    i    d    a |\n",
      "               |    s    q    n    e    n    n    t    x    p    e    t |\n",
      "---------------+--------------------------------------------------------+\n",
      "      No Class |<2290> 276    .   81  700  103   28   89   13   60    . |\n",
      "     topic.acq |  457  <61>   .   13  129   31    4   14    .   10    . |\n",
      "    topic.corn |   42    2   <.>   .    9    1    .    1    .    1    . |\n",
      "   topic.crude |  116   17    .   <4>  36   11    .    3    1    1    . |\n",
      "    topic.earn |  681   82    .   27 <201>  47    5   24    3   18    . |\n",
      "   topic.grain |   87    8    .    2   38   <7>   .    4    .    3    . |\n",
      "topic.interest |   84    9    .    4   26    4   <1>   4    1    .    . |\n",
      "topic.money.fx |  107   17    .    2   44    4    1   <5>   .    .    . |\n",
      "    topic.ship |   64    3    .    2   12    2    .    1   <.>   5    . |\n",
      "   topic.trade |   68   11    .    2   24    6    .    4    .   <2>   . |\n",
      "   topic.wheat |   50    4    .    .    9    7    .    .    .    1   <.>|\n",
      "---------------+--------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the Confusion Matrix SVM\n",
    "from nltk.metrics import ConfusionMatrix \n",
    "import numpy as np\n",
    "\n",
    "trueValues =  classTestList\n",
    "calculatedValues = resultSVM.tolist()\n",
    "confusionMatrixSVM = ConfusionMatrix(trueValues, calculatedValues)\n",
    "print(confusionMatrixSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to calculate Stats \n",
    "from collections import Counter\n",
    "\n",
    "def CalculateStats(confusionMatrix):\n",
    "    labels = ['No Class','topic.acq','topic.corn','topic.crude','topic.earn','topic.grain','topic.interest',\n",
    "              'topic.money.fx','topic.ship','topic.trade']\n",
    "    true_positives = Counter()\n",
    "    false_negatives = Counter()\n",
    "    false_positives = Counter()\n",
    "\n",
    "    for i in labels:\n",
    "        for j in labels:\n",
    "            if i == j:\n",
    "                true_positives[i] += confusionMatrix[i,j]\n",
    "            else:\n",
    "                false_negatives[i] += confusionMatrix[i,j]\n",
    "                false_positives[j] += confusionMatrix[i,j]\n",
    "\n",
    "    for i in sorted(labels):\n",
    "        if true_positives[i] == 0:\n",
    "            fscore = 0\n",
    "        else:\n",
    "            precision = true_positives[i] / float(true_positives[i]+false_positives[i])\n",
    "            recall = true_positives[i] / float(true_positives[i]+false_negatives[i])\n",
    "            fscore = 2 * (precision * recall) / float(precision + recall)\n",
    "        print (i, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Class 0.5662718556119571\n",
      "topic.acq 0.10795040116703135\n",
      "topic.corn 0\n",
      "topic.crude 0.028089887640449437\n",
      "topic.earn 0.18458859381802348\n",
      "topic.grain 0.04129793510324484\n",
      "topic.interest 0.02531645569620253\n",
      "topic.money.fx 0.029239766081871343\n",
      "topic.ship 0.023255813953488372\n",
      "topic.trade 0.024291497975708502\n"
     ]
    }
   ],
   "source": [
    "CalculateStats(confusionMatrixRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Class 0.44253269098417064\n",
      "topic.acq 0.1614481409001957\n",
      "topic.corn 0.017699115044247787\n",
      "topic.crude 0.035532994923857864\n",
      "topic.earn 0.1705357142857143\n",
      "topic.grain 0.013605442176870748\n",
      "topic.interest 0.026246719160104987\n",
      "topic.money.fx 0.03194888178913738\n",
      "topic.ship 0.027303754266211604\n",
      "topic.trade 0.02364066193853428\n"
     ]
    }
   ],
   "source": [
    "CalculateStats(confusionMatrixNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Class 0.5997904662126767\n",
      "topic.acq 0.1012448132780083\n",
      "topic.corn 0\n",
      "topic.crude 0.024539877300613494\n",
      "topic.earn 0.17425227568270482\n",
      "topic.grain 0.038356164383561646\n",
      "topic.interest 0.011627906976744186\n",
      "topic.money.fx 0.0303951367781155\n",
      "topic.ship 0\n",
      "topic.trade 0.018433179723502308\n"
     ]
    }
   ],
   "source": [
    "CalculateStats(confusionMatrixSVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
